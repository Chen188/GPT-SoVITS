{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "096b3004",
   "metadata": {},
   "source": [
    "# GPT-SoVITS on Sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ec2e51",
   "metadata": {},
   "source": [
    "## build image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fd36b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "Cloning into 'GPT-SoVITS'...\n",
      "remote: Enumerating objects: 2628, done.\u001b[K\n",
      "remote: Counting objects: 100% (66/66), done.\u001b[K\n",
      "remote: Compressing objects: 100% (28/28), done.\u001b[K\n",
      "remote: Total 2628 (delta 40), reused 64 (delta 38), pack-reused 2562\u001b[K\n",
      "Receiving objects: 100% (2628/2628), 6.46 MiB | 24.88 MiB/s, done.\n",
      "Resolving deltas: 100% (1442/1442), done.\n",
      "Sending build context to Docker daemon     26MB\n",
      "Step 1/22 : FROM cnstark/pytorch:2.0.1-py3.9.17-cuda11.8.0-ubuntu20.04\n",
      " ---> 8fd9e4c5e7bc\n",
      "Step 2/22 : ARG IMAGE_TYPE=sagemaker-byoc\n",
      " ---> Using cache\n",
      " ---> 61c671c10000\n",
      "Step 3/22 : RUN mkdir -p /opt/program\n",
      " ---> Using cache\n",
      " ---> 55ab582b8ed0\n",
      "Step 4/22 : RUN chmod 777 /opt/program\n",
      " ---> Using cache\n",
      " ---> 958037e745c6\n",
      "Step 5/22 : RUN pip install --no-cache-dir  sagemaker\n",
      " ---> Using cache\n",
      " ---> 32bf46225070\n",
      "Step 6/22 : RUN pip install sagemaker-ssh-helper\n",
      " ---> Using cache\n",
      " ---> 199f93c85551\n",
      "Step 7/22 : RUN pip install boto3\n",
      " ---> Using cache\n",
      " ---> ac2a2e987ca7\n",
      "Step 8/22 : RUN pip3 install pydantic\n",
      " ---> Using cache\n",
      " ---> 94074b08a516\n",
      "Step 9/22 : ENV PYTHONUNBUFFERED=TRUE\n",
      " ---> Using cache\n",
      " ---> 41242972f677\n",
      "Step 10/22 : ENV PYTHONDONTWRITEBYTECODE=TRUE\n",
      " ---> Using cache\n",
      " ---> 1a01dd5d38bd\n",
      "Step 11/22 : ENV PATH=\"/opt/program:${PATH}\"\n",
      " ---> Using cache\n",
      " ---> e4a20b31032b\n",
      "Step 12/22 : ENV DEBIAN_FRONTEND=noninteractive\n",
      " ---> Using cache\n",
      " ---> 53ebc9199e68\n",
      "Step 13/22 : ENV TZ=Etc/UTC\n",
      " ---> Using cache\n",
      " ---> 4da38d18f807\n",
      "Step 14/22 : RUN apt-get update &&     apt-get install -y --no-install-recommends tzdata ffmpeg libsox-dev parallel aria2 git git-lfs &&     git lfs install &&     rm -rf /var/lib/apt/lists/*\n",
      " ---> Using cache\n",
      " ---> 27af75d2d732\n",
      "Step 15/22 : COPY ./GPT-SoVITS /opt/program/\n",
      " ---> f34997fe9704\n",
      "Step 16/22 : WORKDIR /opt/program\n",
      " ---> Running in 49f25b5f5cb5\n",
      "Removing intermediate container 49f25b5f5cb5\n",
      " ---> 4f04ade83f6a\n",
      "Step 17/22 : RUN pip install --no-cache-dir -r /opt/program/requirements.txt\n",
      " ---> Running in b0d4e1e051aa\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.9/site-packages (from -r /opt/program/requirements.txt (line 1)) (1.25.1)\n",
      "Collecting scipy (from -r /opt/program/requirements.txt (line 2))\n",
      "  Downloading scipy-1.13.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 38.6/38.6 MB 280.5 MB/s eta 0:00:00\n",
      "Collecting tensorboard (from -r /opt/program/requirements.txt (line 3))\n",
      "  Downloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.5/5.5 MB 277.8 MB/s eta 0:00:00\n",
      "Collecting librosa==0.9.2 (from -r /opt/program/requirements.txt (line 4))\n",
      "  Downloading librosa-0.9.2-py3-none-any.whl (214 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 214.3/214.3 kB 264.8 MB/s eta 0:00:00\n",
      "Collecting numba==0.56.4 (from -r /opt/program/requirements.txt (line 5))\n",
      "  Downloading numba-0.56.4-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.5 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.5/3.5 MB 272.7 MB/s eta 0:00:00\n",
      "Collecting pytorch-lightning (from -r /opt/program/requirements.txt (line 6))\n",
      "  Downloading pytorch_lightning-2.2.4-py3-none-any.whl (802 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 802.2/802.2 kB 290.2 MB/s eta 0:00:00\n",
      "Collecting gradio==3.38.0 (from -r /opt/program/requirements.txt (line 7))\n",
      "  Downloading gradio-3.38.0-py3-none-any.whl (19.8 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 19.8/19.8 MB 273.3 MB/s eta 0:00:00\n",
      "Collecting gradio_client==0.8.1 (from -r /opt/program/requirements.txt (line 8))\n",
      "  Downloading gradio_client-0.8.1-py3-none-any.whl (305 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 305.2/305.2 kB 193.4 MB/s eta 0:00:00\n",
      "Collecting ffmpeg-python (from -r /opt/program/requirements.txt (line 9))\n",
      "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
      "Collecting onnxruntime (from -r /opt/program/requirements.txt (line 10))\n",
      "  Downloading onnxruntime-1.17.3-cp39-cp39-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.8/6.8 MB 285.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/site-packages (from -r /opt/program/requirements.txt (line 11)) (4.66.4)\n",
      "Collecting funasr==1.0.0 (from -r /opt/program/requirements.txt (line 12))\n",
      "  Downloading funasr-1.0.0-py3-none-any.whl (544 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 544.1/544.1 kB 266.0 MB/s eta 0:00:00\n",
      "Collecting cn2an (from -r /opt/program/requirements.txt (line 13))\n",
      "  Downloading cn2an-0.5.22-py3-none-any.whl (224 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 225.0/225.0 kB 278.5 MB/s eta 0:00:00\n",
      "Collecting pypinyin (from -r /opt/program/requirements.txt (line 14))\n",
      "  Downloading pypinyin-0.51.0-py2.py3-none-any.whl (1.4 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.4/1.4 MB 275.2 MB/s eta 0:00:00\n",
      "Collecting pyopenjtalk (from -r /opt/program/requirements.txt (line 15))\n",
      "  Downloading pyopenjtalk-0.3.3.tar.gz (1.6 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.6/1.6 MB 271.6 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Installing backend dependencies: started\n",
      "  Installing backend dependencies: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting g2p_en (from -r /opt/program/requirements.txt (line 16))\n",
      "  Downloading g2p_en-2.1.0-py3-none-any.whl (3.1 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.1/3.1 MB 252.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: torchaudio in /usr/local/lib/python3.9/site-packages (from -r /opt/program/requirements.txt (line 17)) (2.0.2+cu118)\n",
      "Collecting modelscope==1.10.0 (from -r /opt/program/requirements.txt (line 18))\n",
      "  Downloading modelscope-1.10.0-py3-none-any.whl (5.4 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.4/5.4 MB 223.4 MB/s eta 0:00:00\n",
      "Collecting sentencepiece (from -r /opt/program/requirements.txt (line 19))\n",
      "  Downloading sentencepiece-0.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 271.3 MB/s eta 0:00:00\n",
      "Collecting transformers (from -r /opt/program/requirements.txt (line 20))\n",
      "  Downloading transformers-4.40.2-py3-none-any.whl (9.0 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 9.0/9.0 MB 249.4 MB/s eta 0:00:00\n",
      "Collecting chardet (from -r /opt/program/requirements.txt (line 21))\n",
      "  Downloading chardet-5.2.0-py3-none-any.whl (199 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 199.4/199.4 kB 279.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.9/site-packages (from -r /opt/program/requirements.txt (line 22)) (6.0.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.9/site-packages (from -r /opt/program/requirements.txt (line 23)) (5.9.8)\n",
      "Collecting jieba_fast (from -r /opt/program/requirements.txt (line 24))\n",
      "  Downloading jieba_fast-0.53.tar.gz (7.5 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.5/7.5 MB 238.2 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting jieba (from -r /opt/program/requirements.txt (line 25))\n",
      "  Downloading jieba-0.42.1.tar.gz (19.2 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 19.2/19.2 MB 283.8 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n"
     ]
    }
   ],
   "source": [
    "!chmod +x ./*.sh && ./build_and_push.sh "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11514ade-df1c-4260-8797-83bfc5b279e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import Model, image_uris, serializers, deserializers\n",
    "\n",
    "role = sagemaker.get_execution_role()  # execution role for the endpoint\n",
    "sess = sagemaker.session.Session()  # sagemaker session for interacting with different AWS APIs\n",
    "region = sess._region_name  # region name of the current SageMaker Studio environment\n",
    "account_id = sess.account_id()  # account_id of the current SageMaker Studio environment\n",
    "bucket = sess.default_bucket()\n",
    "image=\"gpt-sovits-inference\"\n",
    "s3_client = boto3.client(\"s3\")\n",
    "sm_client = boto3.client(\"sagemaker\")\n",
    "smr_client = boto3.client(\"sagemaker-runtime\")\n",
    "\n",
    "full_image_uri=f\"{account_id}.dkr.ecr.{region}.amazonaws.com/{image}:latest\"\n",
    "print(full_image_uri)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54bf5b1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## remote debug test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131fe9fa-f2a3-49e0-8a83-156b00980d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## empty model data for byoc with webserver\n",
    "!touch dummy\n",
    "!tar czvf model.tar.gz dummy\n",
    "assets_dir = 's3://{0}/{1}/assets/'.format(bucket, 'gpt_sovits')\n",
    "model_data = 's3://{0}/{1}/assets/model.tar.gz'.format(bucket, 'gpt_sovits')\n",
    "!aws s3 cp model.tar.gz $assets_dir\n",
    "!rm -f dummy model.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a45469-989b-4709-bc1f-8c6a59ac6fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker_ssh_helper.wrapper import SSHModelWrapper\n",
    "model = Model(image_uri=full_image_uri, model_data=model_data, role=role,dependencies=[SSHModelWrapper.dependency_dir()] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e60433-09e8-449e-9fc5-6fbd639d98f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker_ssh_helper.wrapper import SSHModelWrapper\n",
    "instance_type = \"ml.g5.xlarge\"\n",
    "endpoint_name = sagemaker.utils.name_from_base(\"gpt-sovits-inference\")\n",
    "\n",
    "\n",
    "ssh_wrapper = SSHModelWrapper.create(model, connection_wait_time_seconds=0)  # <--NEW--\n",
    "\n",
    "predictor = model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=instance_type,\n",
    "    endpoint_name=endpoint_name,\n",
    "    wait=False\n",
    ")\n",
    "\n",
    "\n",
    "#instance_ids = ssh_wrapper.get_instance_ids(timeout_in_sec=900)  # <--NEW-- \n",
    "#print(f\"To connect over SSM run: aws ssm start-session --target {instance_ids[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049dd079-5fc7-4bd1-a473-0a19901cc390",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "instance_ids = ssh_wrapper.get_instance_ids(timeout_in_sec=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64f214c-f125-44a8-ae46-0efc7b230d12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "instance_ids[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abe8919-0bb9-43c0-8d03-4a2a2a1e9a2e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## SM endpoint test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1663aa2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### create sagemaker model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3623fcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "import uuid\n",
    "import boto3\n",
    "import sagemaker\n",
    "from time import gmtime, strftime\n",
    "## for debug only\n",
    "from sagemaker_ssh_helper.wrapper import SSHModelWrapper\n",
    "sm_client = boto3.client(service_name='sagemaker')\n",
    "\n",
    "\n",
    "\n",
    "def create_model():\n",
    "    image=full_image_uri\n",
    "    model_name=\"gpt-sovits-sagemaker-\"+strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "    create_model_response = sm_client.create_model(\n",
    "        ModelName=model_name,\n",
    "        ExecutionRoleArn=role,\n",
    "        Containers=[{\"Image\": image}],\n",
    "    )\n",
    "    print(create_model_response)\n",
    "    return model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e913d8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=create_model()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4159960d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### create endpoint configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b4ba47",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpointConfigName = \"gpt-sovits-sagemaker-configuration-\"+strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "def create_endpoint_configuration():\n",
    "    create_endpoint_config_response = sm_client.create_endpoint_config(     \n",
    "        EndpointConfigName=endpointConfigName,\n",
    "        ProductionVariants=[\n",
    "            {\n",
    "                #\"ModelName\":\"gpt-sovits-sagemaker-012024-03-28-04-00-03\",\n",
    "                \"ModelName\":model_name,\n",
    "                \"VariantName\": \"gpt-sovits-sagemaker\"+\"-variant\",\n",
    "                \"InstanceType\": \"ml.g5.xlarge\",  # 指定 g5.xlarge 机器\n",
    "                \"InitialInstanceCount\": 1,\n",
    "                \"ModelDataDownloadTimeoutInSeconds\": 1200,\n",
    "                \"ContainerStartupHealthCheckTimeoutInSeconds\": 1200\n",
    "            }\n",
    "        ],\n",
    "    )\n",
    "    print(create_endpoint_config_response)\n",
    "    return endpointConfigName\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06fb9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_endpoint_configuration()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e35082",
   "metadata": {
    "tags": []
   },
   "source": [
    "### create endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40abb7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpointName=\"gpt-sovits-sagemaker-endpoint\"+strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "def create_endpoint():\n",
    "    create_endpoint_response = sm_client.create_endpoint(\n",
    "        EndpointName=endpointName,\n",
    "        #EndpointConfigName=\"gpt-sovits-sagemaker-configuration2024-03-28-04-03-53\",\n",
    "        EndpointConfigName=endpointConfigName\n",
    "    )\n",
    "    print(\"Endpoint Arn: \" + create_endpoint_response[\"EndpointArn\"])\n",
    "    resp = sm_client.describe_endpoint(EndpointName=endpointName)\n",
    "    print(\"Endpoint Status: \" + resp[\"EndpointStatus\"])\n",
    "    print(\"Waiting for {} endpoint to be in service\".format(\"gpt-sovits-sagemaker-endpoint\"))\n",
    "    waiter = sm_client.get_waiter(\"endpoint_in_service\")\n",
    "    waiter.wait(EndpointName=endpointName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adeafb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3594fc7d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Realtime inferecne with sagemaker endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4dae12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "endpointName=\"gpt-sovits-inference-2024-05-07-08-46-43-537\"\n",
    "runtime_sm_client = boto3.client(service_name=\"sagemaker-runtime\")\n",
    "#endpointName=\"gpt-sovits-sagemaker-endpoint2024-04-03-23-49-44\"\n",
    "\n",
    "\n",
    "request = {\"refer_wav_path\":\"s3://sagemaker-us-west-2-687912291502/gpt-sovits/wav/speech_20240425104005663.mp3\",\n",
    "    \"prompt_text\": \"私はスポーツが好きな女の子で、私は中華料理が大好きで、私は中国へ旅行するのが好きで、特に杭州、成都が好きです\",\n",
    "    \"prompt_language\":\"ja\",\n",
    "    \"text\":\"あなたは四海を家とすることを約束します,私を待っていても気にしないで、あなたの白髪を許す\",\n",
    "    \"text_language\" :\"ja\",\n",
    "    \"output_s3uri\":\"s3://sagemaker-us-west-2-687912291502/gpt_sovits_output/wav/\"}\n",
    "\n",
    "\n",
    "request = {\"refer_wav_path\":\"s3://sagemaker-us-west-2-687912291502/gpt-sovits/wav/123.WAV.wav\",\n",
    "    \"prompt_text\": \"早上好，欢迎来到我的一天，这是我做音频主播的第四个年头了，有小伙伴留言想让我分享一些音频直播的经验，今天我先和大家聊聊我的入行原因。其实我从中选情就很喜欢电台了，在校期间眼睛记得参加各类广播站以及校园主持的活动，我好像对话筒和声音就有一种莫名的执念，所以在17年里的时候，我创建了一个自己的电台公众号，通过声音和文字记录自己的一些心事。后来18年底经由朋友的介绍，可以通过音频直播分享我写的东西，还有我的声音。当时呢我就想音频直播又不用落脸那么方便，试一试吧，如果有人喜欢，还可以给自己的电台公众号吸吸粉。后来我就在直播间里认识了越来越多的听友，渐渐的这份工作，也为我带来了一些兼职收入，我就决定把这份工作做下去。\",\n",
    "    \"prompt_language\":\"zh\",\n",
    "    \"text\":\"作为SAP基础架构专家,我来解释一下SAP Basis的含义:SAP Basis是指SAP系统的基础设施层,负责管理和维护整个SAP系统环境的运行。它包括以下几个主要方面:SAP系统管理包括SAP系统实例的安装、启动、监控、备份、升级等日常管理任务。Basis团队负责保证系统的正常运行。\",\n",
    "    \"text_language\" :\"zh\",\n",
    "    \"output_s3uri\":\"s3://sagemaker-us-west-2-687912291502/gpt_sovits_output/wav/\"}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def invoke_endpoint():\n",
    "    content_type = \"application/json\"\n",
    "    request_body = request\n",
    "    payload = json.dumps(request_body)\n",
    "    print(payload)\n",
    "    response = runtime_sm_client.invoke_endpoint(\n",
    "        EndpointName=endpointName,\n",
    "        ContentType=content_type,\n",
    "        Body=payload,\n",
    "    )\n",
    "    result = response['Body'].read().decode()\n",
    "    print('返回：',result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01f4489",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response=invoke_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ae7796-8d05-47af-8979-19bdb8c35cfc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!aws s3 cp s3://sagemaker-us-west-2-687912291502/gpt-sovits/wav/speech_20240425104005663.mp3 ./\n",
    "!aws s3 cp s3://sagemaker-us-west-2-687912291502/gpt_sovits_output/wav/gpt_sovits_1715140344.wav ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8817f0c-dd4b-41e4-a6a4-1e601807cbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp s3://sagemaker-us-west-2-687912291502/gpt_sovits_output/wav/gpt_sovits_1715150796.wav ./"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e41b30b-e8f7-4c7f-853f-7d861c12c543",
   "metadata": {},
   "source": [
    "## Streams test (only for stream branch deployment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac28f418-dd4f-4dab-a7cb-412b5048df28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "chunk_bytes=None\n",
    "\n",
    "def upsert(lst, new_dict, key_func):\n",
    "    index = key_func(new_dict)\n",
    "    for i, item in enumerate(lst):\n",
    "        if key_func(item) == index:\n",
    "            lst[i] = new_dict\n",
    "            return lst\n",
    "    lst.append(new_dict)\n",
    "    return lst\n",
    "\n",
    "def invoke_streams_endpoint(smr_client,endpointName, request):\n",
    "    global chunk_bytes\n",
    "    content_type = \"application/json\"\n",
    "    payload = json.dumps(request,ensure_ascii=False)\n",
    "\n",
    "    response_model = smr_client.invoke_endpoint_with_response_stream(\n",
    "        EndpointName=endpointName,\n",
    "        ContentType=content_type,\n",
    "        Body=payload,\n",
    "    )\n",
    "\n",
    "    result = []\n",
    "    print(response_model['ResponseMetadata'])\n",
    "    event_stream = iter(response_model['Body'])\n",
    "    index = 0\n",
    "    try: \n",
    "        while True:\n",
    "            event = next(event_stream)\n",
    "            eventChunk = event['PayloadPart']['Bytes'].decode('utf-8')\n",
    "            print(\"eventChunk\",eventChunk)\n",
    "            chunk_dict = {}\n",
    "            if index == 0:\n",
    "                print(\"Received first chunk\")\n",
    "                chunk_dict['first_chunk'] = True\n",
    "                chunk_dict['bytes'] = eventChunk\n",
    "                chunk_bytes = eventChunk\n",
    "                chunk_dict['last_chunk'] = False\n",
    "                chunk_dict['index'] = index\n",
    "            else:\n",
    "                chunk_dict['first_chunk'] = False\n",
    "                chunk_dict['bytes'] = eventChunk\n",
    "                chunk_bytes = eventChunk\n",
    "                chunk_dict['last_chunk'] = False\n",
    "                chunk_dict['index'] = index\n",
    "            result.append(chunk_dict)    \n",
    "            index += 1\n",
    "            #print('返回chunk：', chunk_dict['bytes'])\n",
    "    except StopIteration:\n",
    "        print(\"All chunks processed\")\n",
    "        chunk_dict = {}\n",
    "        chunk_dict['first_chunk'] = False\n",
    "        chunk_dict['bytes'] = chunk_bytes\n",
    "        chunk_dict['last_chunk'] = True\n",
    "        chunk_dict['index'] = index\n",
    "        result = upsert(result,chunk_dict,lambda item: item['index']==index)\n",
    "    print(\"result\",result)\n",
    "    return result\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da64eb21-35dd-49c0-9356-9b5833fee9d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "endpointName=\"gpt-sovits-inference-2024-05-17-10-03-18-880\"\n",
    "runtime_sm_client = boto3.client(service_name=\"sagemaker-runtime\")\n",
    "#endpointName=\"gpt-sovits-sagemaker-endpoint2024-04-03-23-49-44\"\n",
    "\n",
    "\n",
    "\n",
    "request = {\"refer_wav_path\":\"s3://sagemaker-us-west-2-687912291502/gpt-sovits/wav/123.WAV.wav\",\n",
    "    \"prompt_text\": \"早上好，欢迎来到我的一天，这是我做音频主播的第四个年头了，有小伙伴留言想让我分享一些音频直播的经验，今天我先和大家聊聊我的入行原因。其实我从中选情就很喜欢电台了，在校期间眼睛记得参加各类广播站以及校园主持的活动，我好像对话筒和声音就有一种莫名的执念，所以在17年里的时候，我创建了一个自己的电台公众号，通过声音和文字记录自己的一些心事。后来18年底经由朋友的介绍，可以通过音频直播分享我写的东西，还有我的声音。当时呢我就想音频直播又不用落脸那么方便，试一试吧，如果有人喜欢，还可以给自己的电台公众号吸吸粉。后来我就在直播间里认识了越来越多的听友，渐渐的这份工作，也为我带来了一些兼职收入，我就决定把这份工作做下去。\",\n",
    "    \"prompt_language\":\"zh\",\n",
    "    \"text\":\"作为SAP基础架构专家,我来解释一下SAP Basis的含义:SAP Basis是指SAP系统的基础设施层,负责管理和维护整个SAP系统环境的运行。它包括以下几个主要方面:SAP系统管理包括SAP系统实例的安装、启动、监控、备份、升级等日常管理任务。Basis团队负责保证系统的正常运行。\",\n",
    "    \"text_language\" :\"zh\",\n",
    "    \"output_s3uri\":\"s3://sagemaker-us-west-2-687912291502/gpt_sovits_output/wav/\",\n",
    "    \"cut_punc\":\"。\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b206b8ed-1321-4963-b476-10bff2d985e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response=invoke_streams_endpoint(runtime_sm_client,endpointName,request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1fda29c0-7686-4eb6-878e-0ded9f883638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-us-west-2-687912291502/gpt_sovits_output/wav/gpt_sovits_1715948516.wav to ./gpt_sovits_1715948516.wav\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp s3://sagemaker-us-west-2-687912291502/gpt_sovits_output/wav/gpt_sovits_1715948516.wav ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba2ade1-5bbe-49b5-b3b7-1568641353a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
